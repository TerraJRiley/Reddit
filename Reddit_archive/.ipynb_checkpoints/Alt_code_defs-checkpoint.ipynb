{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "# Executive Summary\n",
    "How many times have you opened up a browser for a random subreddit only to find that it wasn't the random subreddit you were looking for?  We've all been there.  Furthermore, what about when you wonder \"golly, just how similar are different subreddits that are focused one concept but from entirely different points of view?\"  Well, we hear you.  We've scrapped data from two active subreddits which focus around sexuality and using them build a model that's able to detect if it's one subreddit or the other with over an 80% certainty.  Furthermore, if future exploritory data analysis, we hope to one day be able to talk about the defining features of each subculter that's being represented by these subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function that scrapes a subreddit and turns it into a pandas dataframe.\n",
    "Followed by it being used for the actuallesbians, Braincels and Trufemcels subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class subreddit:\n",
    "    def __init__ scrape_reddit(the_subreddit, pages = 40):\n",
    "        all_posts = []\n",
    "        first_url = 'http://www.reddit.com/r/' + the_subreddit + '.json'\n",
    "        url = first_url\n",
    "        list_of_df = []\n",
    "\n",
    "        #Putting in a get check, for happy sanity reasons:\n",
    "        quick_check = requests.get(first_url, headers = {'User-agent':'Electronic Goddess'})\n",
    "        if int(str(quick_check)[11:14]) == 200:\n",
    "            print(\"Get request successful.\")\n",
    "            time.sleep(3)\n",
    "            print(\"Initiating Scrape...\")\n",
    "        else:\n",
    "            print(\"Get request not 200, instead recieved:\" + str(quick_check))\n",
    "            return\n",
    "\n",
    "        #Now for the actual Scraping:\n",
    "        for round in range(pages):\n",
    "            try:\n",
    "                res = requests.get(url, headers = {'User-agent':'Electronic Goddess'})\n",
    "                data = res.json()\n",
    "                list_of_posts = data['data']['children']\n",
    "                all_posts = all_posts + list_of_posts\n",
    "                after = data['data']['after']\n",
    "                url = first_url +'?after=' + after\n",
    "                print('Current After:' + after,'Round: '+ str(round + 1))\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                print('Limit likely hit.  Returning available posts.')\n",
    "                break\n",
    "    #        return all_posts # This can be un-commented out incase I want the straight forward raw scrape\n",
    "\n",
    "        #Formats the parts we care about into a list of dictionaries that'll become the dataframe\n",
    "        for i in range(len(all_posts)):\n",
    "            index_dictionary = {\n",
    "                    'title' : all_posts[i]['data']['title'],\n",
    "                    'selftext': all_posts[i]['data']['selftext'],\n",
    "                    'subreddit' : all_posts[i]['data']['subreddit']\n",
    "                }\n",
    "            list_of_df.append(index_dictionary)\n",
    "        return pd.DataFrame(list_of_df, columns = ['title','selftext','subreddit'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class subreddit:\n",
    "def scrape_reddit(the_subreddit, pages = 40):\n",
    "    print(str(the_subreddit))\n",
    "    all_posts = []\n",
    "    first_url = 'http://www.reddit.com/r/' + the_subreddit + '.json'\n",
    "    url = first_url\n",
    "    list_of_df = []\n",
    "    \n",
    "    #Putting in a get check, for happy sanity reasons:\n",
    "    quick_check = requests.get(first_url, headers = {'User-agent':'Electronic Goddess'})\n",
    "    if int(str(quick_check)[11:14]) == 200:\n",
    "        print(\"Get request successful.\")\n",
    "        time.sleep(3)\n",
    "        print(\"Initiating Scrape...\")\n",
    "    else:\n",
    "        print(\"Get request not 200, instead recieved:\" + str(quick_check))\n",
    "        return\n",
    "    \n",
    "    #Now for the actual Scraping:\n",
    "    for round in range(pages):\n",
    "        try:\n",
    "            res = requests.get(url, headers = {'User-agent':'Electronic Goddess'})\n",
    "            data = res.json()\n",
    "            list_of_posts = data['data']['children']\n",
    "            all_posts = all_posts + list_of_posts\n",
    "            after = data['data']['after']\n",
    "            url = first_url +'?after=' + after\n",
    "            print('Current After:' + after,'Round: '+ str(round + 1))\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            print('Limit likely hit.  Returning available posts.')\n",
    "            break\n",
    "#        return all_posts # This can be un-commented out incase I want the straight forward raw scrape\n",
    "\n",
    "    #Formats the parts we care about into a list of dictionaries that'll become the dataframe\n",
    "    for i in range(len(all_posts)):\n",
    "        index_dictionary = {\n",
    "                'title' : all_posts[i]['data']['title'],\n",
    "                'selftext': all_posts[i]['data']['selftext'],\n",
    "                'subreddit' : all_posts[i]['data']['subreddit']\n",
    "            }\n",
    "        list_of_df.append(index_dictionary)\n",
    "    return pd.DataFrame(list_of_df, columns = ['title','selftext','subreddit'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seduction\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9sapdt Round: 1\n",
      "Current After:t3_9s74no Round: 2\n",
      "Current After:t3_9rz3lu Round: 3\n",
      "Current After:t3_9rsha4 Round: 4\n",
      "Current After:t3_9rmhda Round: 5\n",
      "Current After:t3_9r4yt4 Round: 6\n",
      "Current After:t3_9r69w1 Round: 7\n",
      "Current After:t3_9qtqvb Round: 8\n",
      "Current After:t3_9qg03e Round: 9\n",
      "Current After:t3_9q9u3s Round: 10\n",
      "Current After:t3_9q1q7t Round: 11\n",
      "Current After:t3_9pps3p Round: 12\n",
      "Current After:t3_9pj9wk Round: 13\n",
      "Current After:t3_9p6tgg Round: 14\n",
      "Current After:t3_9p1y79 Round: 15\n",
      "Current After:t3_9ogi2h Round: 16\n",
      "Current After:t3_9omudq Round: 17\n",
      "Current After:t3_9oeumo Round: 18\n",
      "Current After:t3_9o62zr Round: 19\n",
      "Current After:t3_9nsffn Round: 20\n",
      "Current After:t3_9nminb Round: 21\n",
      "Current After:t3_9nde2d Round: 22\n",
      "Current After:t3_9n3qds Round: 23\n",
      "Current After:t3_9modtz Round: 24\n",
      "Current After:t3_9mg242 Round: 25\n",
      "Current After:t3_9m09oh Round: 26\n",
      "Current After:t3_9m4dol Round: 27\n",
      "Current After:t3_9m0abt Round: 28\n",
      "Current After:t3_9lo2jy Round: 29\n",
      "Current After:t3_9lgz7l Round: 30\n",
      "Current After:t3_9l91ig Round: 31\n",
      "Current After:t3_9ky1x2 Round: 32\n",
      "Current After:t3_9kiiq2 Round: 33\n",
      "Current After:t3_9k648n Round: 34\n",
      "Current After:t3_9k6li9 Round: 35\n",
      "Current After:t3_9jw7mx Round: 36\n",
      "Current After:t3_9j9505 Round: 37\n",
      "Current After:t3_9jd6fa Round: 38\n",
      "Limit likely hit.  Returning available posts.\n",
      "puascience\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_22uegq Round: 1\n",
      "Limit likely hit.  Returning available posts.\n",
      "pickup\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9lxvfo Round: 1\n",
      "Current After:t3_964nop Round: 2\n",
      "Current After:t3_8u3756 Round: 3\n",
      "Current After:t3_8k0kl9 Round: 4\n",
      "Current After:t3_8dte66 Round: 5\n",
      "Current After:t3_89l8l1 Round: 6\n",
      "Current After:t3_82slol Round: 7\n",
      "Current After:t3_7wsswy Round: 8\n",
      "Current After:t3_7shyyi Round: 9\n",
      "Current After:t3_7osk1q Round: 10\n",
      "Current After:t3_7m78v3 Round: 11\n",
      "Current After:t3_7l2lo5 Round: 12\n",
      "Current After:t3_7itw5o Round: 13\n",
      "Current After:t3_7g9bze Round: 14\n",
      "Current After:t3_7cys4y Round: 15\n",
      "Current After:t3_7aicbl Round: 16\n",
      "Current After:t3_77gshl Round: 17\n",
      "Current After:t3_733iyx Round: 18\n",
      "Current After:t3_6x3ft5 Round: 19\n",
      "Current After:t3_6swfcj Round: 20\n",
      "Current After:t3_6q1548 Round: 21\n",
      "Current After:t3_6m8xqt Round: 22\n",
      "Current After:t3_6k33d6 Round: 23\n",
      "Current After:t3_6jb2ym Round: 24\n",
      "Current After:t3_6hevyb Round: 25\n",
      "Current After:t3_6btgiz Round: 26\n",
      "Current After:t3_68lc6p Round: 27\n",
      "Current After:t3_65t3b6 Round: 28\n",
      "Current After:t3_63c4qa Round: 29\n",
      "Current After:t3_60rxwd Round: 30\n",
      "Current After:t3_5wl0a1 Round: 31\n",
      "Current After:t3_5qv3vd Round: 32\n",
      "Current After:t3_uikeu Round: 33\n",
      "Current After:t3_tig5q Round: 34\n",
      "Current After:t3_t0u5u Round: 35\n",
      "Current After:t3_spej3 Round: 36\n",
      "Limit likely hit.  Returning available posts.\n",
      "pua\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Limit likely hit.  Returning available posts.\n",
      "lgbt\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9sekgo Round: 1\n",
      "Current After:t3_9sd3na Round: 2\n",
      "Current After:t3_9scc2d Round: 3\n",
      "Current After:t3_9s3fr6 Round: 4\n",
      "Current After:t3_9s2sct Round: 5\n",
      "Current After:t3_9s0bsk Round: 6\n",
      "Current After:t3_9ru3u8 Round: 7\n",
      "Current After:t3_9rox5r Round: 8\n",
      "Current After:t3_9rrh93 Round: 9\n",
      "Current After:t3_9rg0yz Round: 10\n",
      "Current After:t3_9rfy63 Round: 11\n",
      "Current After:t3_9rcdlu Round: 12\n",
      "Current After:t3_9r8qme Round: 13\n",
      "Current After:t3_9r3aoq Round: 14\n",
      "Current After:t3_9r3rla Round: 15\n",
      "Current After:t3_9qvsxy Round: 16\n",
      "Current After:t3_9qreka Round: 17\n",
      "Current After:t3_9qth96 Round: 18\n",
      "Current After:t3_9qjhne Round: 19\n",
      "Current After:t3_9ql7ge Round: 20\n",
      "Current After:t3_9ql7g6 Round: 21\n",
      "Current After:t3_9qco97 Round: 22\n",
      "Current After:t3_9qagsy Round: 23\n",
      "Current After:t3_9q42lr Round: 24\n",
      "Current After:t3_9q2z74 Round: 25\n",
      "Current After:t3_9pv25h Round: 26\n",
      "Current After:t3_9q47ab Round: 27\n",
      "Current After:t3_9q1iap Round: 28\n",
      "Current After:t3_9pyyfh Round: 29\n",
      "Current After:t3_9pmn3d Round: 30\n",
      "Current After:t3_9ph03h Round: 31\n",
      "Current After:t3_9pgd7v Round: 32\n",
      "Current After:t3_9p7cg3 Round: 33\n",
      "Current After:t3_9p85b4 Round: 34\n",
      "Current After:t3_9p4p8e Round: 35\n",
      "Current After:t3_9p63ko Round: 36\n",
      "Current After:t3_9oz7fk Round: 37\n",
      "Current After:t3_9owc6o Round: 38\n",
      "Limit likely hit.  Returning available posts.\n",
      "ainbow\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9rvcf7 Round: 1\n",
      "Current After:t3_9rkzp3 Round: 2\n",
      "Current After:t3_9re4sh Round: 3\n",
      "Current After:t3_9r1cw1 Round: 4\n",
      "Current After:t3_9qt3mo Round: 5\n",
      "Current After:t3_9qfsqe Round: 6\n",
      "Current After:t3_9pva9y Round: 7\n",
      "Current After:t3_9ppzu4 Round: 8\n",
      "Current After:t3_9p9k5z Round: 9\n",
      "Current After:t3_9oxsbs Round: 10\n",
      "Current After:t3_9oh2cp Round: 11\n",
      "Current After:t3_9o2jl4 Round: 12\n",
      "Current After:t3_9nfr3w Round: 13\n",
      "Current After:t3_9ncb36 Round: 14\n",
      "Current After:t3_9n2yqg Round: 15\n",
      "Current After:t3_9mqlzd Round: 16\n",
      "Current After:t3_9lzzzr Round: 17\n",
      "Current After:t3_9kyzyo Round: 18\n",
      "Current After:t3_9kmt8m Round: 19\n",
      "Current After:t3_9jhcd7 Round: 20\n",
      "Current After:t3_9iy29f Round: 21\n",
      "Current After:t3_9hztk9 Round: 22\n",
      "Current After:t3_9hizy6 Round: 23\n",
      "Current After:t3_9hai5e Round: 24\n",
      "Current After:t3_9ghvf4 Round: 25\n",
      "Current After:t3_9ge57w Round: 26\n",
      "Current After:t3_9g3sca Round: 27\n",
      "Current After:t3_9ftotw Round: 28\n",
      "Current After:t3_9fm6xw Round: 29\n",
      "Current After:t3_9erwlt Round: 30\n",
      "Current After:t3_9e3cn2 Round: 31\n",
      "Current After:t3_9d15sb Round: 32\n",
      "Current After:t3_9cl3jl Round: 33\n",
      "Current After:t3_9bxjsg Round: 34\n",
      "Current After:t3_9b5wwc Round: 35\n",
      "Current After:t3_9al3kz Round: 36\n",
      "Current After:t3_99sb5k Round: 37\n",
      "Current After:t3_996l0z Round: 38\n",
      "Limit likely hit.  Returning available posts.\n",
      "AskLGBT\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9mkc1s Round: 1\n",
      "Current After:t3_9h2y1v Round: 2\n",
      "Current After:t3_996fx5 Round: 3\n",
      "Current After:t3_93h175 Round: 4\n",
      "Current After:t3_8udwsg Round: 5\n",
      "Current After:t3_8oa3cp Round: 6\n",
      "Current After:t3_8iryrm Round: 7\n",
      "Current After:t3_8c4wuu Round: 8\n",
      "Current After:t3_82agr9 Round: 9\n",
      "Current After:t3_7rkx3v Round: 10\n",
      "Current After:t3_7gtr9p Round: 11\n",
      "Current After:t3_74ctx9 Round: 12\n",
      "Current After:t3_6sbu8i Round: 13\n",
      "Current After:t3_6hadjm Round: 14\n",
      "Current After:t3_69bcgm Round: 15\n",
      "Current After:t3_5zsv7l Round: 16\n",
      "Current After:t3_5lnm19 Round: 17\n",
      "Current After:t3_581r6f Round: 18\n",
      "Current After:t3_4tpbpg Round: 19\n",
      "Current After:t3_4dsctm Round: 20\n",
      "Current After:t3_3zwvfr Round: 21\n",
      "Current After:t3_3tgzdn Round: 22\n",
      "Current After:t3_3htrjj Round: 23\n",
      "Current After:t3_35vdu5 Round: 24\n",
      "Current After:t3_2xhnjz Round: 25\n",
      "Current After:t3_2marde Round: 26\n",
      "Current After:t3_2b029m Round: 27\n",
      "Current After:t3_222zwn Round: 28\n",
      "Current After:t3_1si7zu Round: 29\n",
      "Current After:t3_k4bla Round: 30\n",
      "Limit likely hit.  Returning available posts.\n",
      "happentobegay\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_n0vhi Round: 1\n",
      "Current After:t3_m7dng Round: 2\n",
      "Limit likely hit.  Returning available posts.\n",
      "glbt\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_5ckfr3 Round: 1\n",
      "Current After:t3_23pjj8 Round: 2\n",
      "Current After:t3_1g4tcs Round: 3\n",
      "Current After:t3_19yqm8 Round: 4\n",
      "Current After:t3_11pagy Round: 5\n",
      "Current After:t3_t3gyp Round: 6\n",
      "Current After:t3_ouj3b Round: 7\n",
      "Current After:t3_inyj6 Round: 8\n",
      "Current After:t3_er17j Round: 9\n",
      "Current After:t3_1nlxnz Round: 10\n",
      "Current After:t3_dhc6b Round: 11\n",
      "Limit likely hit.  Returning available posts.\n",
      "gay\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9s05by Round: 1\n",
      "Current After:t3_9rzdbq Round: 2\n",
      "Current After:t3_9rox97 Round: 3\n",
      "Current After:t3_9rgjun Round: 4\n",
      "Current After:t3_9qzz2g Round: 5\n",
      "Current After:t3_9r2suv Round: 6\n",
      "Current After:t3_9qwfiz Round: 7\n",
      "Current After:t3_9qjps4 Round: 8\n",
      "Current After:t3_9qa4jq Round: 9\n",
      "Current After:t3_9q1hll Round: 10\n",
      "Current After:t3_9pqelh Round: 11\n",
      "Current After:t3_9pf92m Round: 12\n",
      "Current After:t3_9p7aj8 Round: 13\n",
      "Current After:t3_9oy0z1 Round: 14\n",
      "Current After:t3_9ospg8 Round: 15\n",
      "Current After:t3_9oe2pm Round: 16\n",
      "Current After:t3_9ob7l8 Round: 17\n",
      "Current After:t3_9nmrzi Round: 18\n",
      "Current After:t3_9ng2tw Round: 19\n",
      "Current After:t3_9ndcb3 Round: 20\n",
      "Current After:t3_9mvv0t Round: 21\n",
      "Current After:t3_9mb3x0 Round: 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current After:t3_9mc4aw Round: 23\n",
      "Current After:t3_9maiep Round: 24\n",
      "Current After:t3_9lty5l Round: 25\n",
      "Current After:t3_9llgq2 Round: 26\n",
      "Current After:t3_9l19mr Round: 27\n",
      "Current After:t3_9krs81 Round: 28\n",
      "Current After:t3_9k69t6 Round: 29\n",
      "Current After:t3_9k2m0b Round: 30\n",
      "Current After:t3_9jy9ju Round: 31\n",
      "Current After:t3_9jhfdh Round: 32\n",
      "Current After:t3_9jcm8b Round: 33\n",
      "Current After:t3_9j0atk Round: 34\n",
      "Current After:t3_9inss6 Round: 35\n",
      "Current After:t3_9ievbw Round: 36\n",
      "Current After:t3_9i9fly Round: 37\n",
      "Current After:t3_9hl8z7 Round: 38\n",
      "Limit likely hit.  Returning available posts.\n",
      "lgb\n",
      "Get request not 200, instead recieved:<Response [403]>\n",
      "gayrights\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_7lbche Round: 1\n",
      "Current After:t3_5wykfh Round: 2\n",
      "Current After:t3_4hfeuj Round: 3\n",
      "Current After:t3_3lso22 Round: 4\n",
      "Current After:t3_385t3z Round: 5\n",
      "Current After:t3_2xsrc2 Round: 6\n",
      "Current After:t3_2jnw8t Round: 7\n",
      "Current After:t3_25dklo Round: 8\n",
      "Current After:t3_1zkb03 Round: 9\n",
      "Current After:t3_1myq5m Round: 10\n",
      "Current After:t3_1h4ebh Round: 11\n",
      "Current After:t3_1bo1o5 Round: 12\n",
      "Current After:t3_1aahvt Round: 13\n",
      "Current After:t3_11yvy3 Round: 14\n",
      "Current After:t3_vlbyf Round: 15\n",
      "Current After:t3_pxsu6 Round: 16\n",
      "Current After:t3_izi77 Round: 17\n",
      "Current After:t3_9ndtl Round: 18\n",
      "Current After:t3_11wiyr Round: 19\n",
      "Limit likely hit.  Returning available posts.\n",
      "LGBTVent\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Limit likely hit.  Returning available posts.\n",
      "lgbtsex\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_90tkvm Round: 1\n",
      "Current After:t3_8magui Round: 2\n",
      "Current After:t3_7z2sey Round: 3\n",
      "Current After:t3_78456p Round: 4\n",
      "Current After:t3_62uanj Round: 5\n",
      "Current After:t3_5pt95w Round: 6\n",
      "Current After:t3_5exxe7 Round: 7\n",
      "Limit likely hit.  Returning available posts.\n",
      "queer\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9fxtem Round: 1\n",
      "Current After:t3_97hkhe Round: 2\n",
      "Current After:t3_8yi7q6 Round: 3\n",
      "Current After:t3_8pqt44 Round: 4\n",
      "Current After:t3_8i8vvu Round: 5\n",
      "Current After:t3_7y0dj8 Round: 6\n",
      "Current After:t3_75d1vp Round: 7\n",
      "Current After:t3_6r8get Round: 8\n",
      "Current After:t3_6g4h4n Round: 9\n",
      "Current After:t3_5sp4y6 Round: 10\n",
      "Current After:t3_4xscj8 Round: 11\n",
      "Current After:t3_4ab62a Round: 12\n",
      "Current After:t3_3urni0 Round: 13\n",
      "Current After:t3_3h3nuh Round: 14\n",
      "Current After:t3_3akzh7 Round: 15\n",
      "Current After:t3_315yc0 Round: 16\n",
      "Current After:t3_2mqnsb Round: 17\n",
      "Current After:t3_21xbp7 Round: 18\n",
      "Current After:t3_1nzmi5 Round: 19\n",
      "Current After:t3_18lnoc Round: 20\n",
      "Current After:t3_nvtnj Round: 21\n",
      "Current After:t3_hthva Round: 22\n",
      "Current After:t3_dm6ij Round: 23\n",
      "Current After:t3_cb1oa Round: 24\n",
      "Limit likely hit.  Returning available posts.\n",
      "asexual\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9o60cs Round: 1\n",
      "Current After:t3_9k5tfd Round: 2\n",
      "Current After:t3_9fc07h Round: 3\n",
      "Current After:t3_9982nk Round: 4\n",
      "Current After:t3_9383gc Round: 5\n",
      "Current After:t3_8xzgov Round: 6\n",
      "Current After:t3_8ub31v Round: 7\n",
      "Current After:t3_8qldfx Round: 8\n",
      "Current After:t3_8nyvnn Round: 9\n",
      "Current After:t3_8ibq8b Round: 10\n",
      "Current After:t3_8exrs1 Round: 11\n",
      "Current After:t3_8afkbh Round: 12\n",
      "Current After:t3_82dbpa Round: 13\n",
      "Current After:t3_7yh278 Round: 14\n",
      "Current After:t3_7tnmra Round: 15\n",
      "Current After:t3_7nj1hl Round: 16\n",
      "Current After:t3_7ibbd0 Round: 17\n",
      "Current After:t3_7dwcos Round: 18\n",
      "Current After:t3_7aiqu7 Round: 19\n",
      "Current After:t3_773blx Round: 20\n",
      "Current After:t3_728tzw Round: 21\n",
      "Current After:t3_6x0hnl Round: 22\n",
      "Current After:t3_6t0qfo Round: 23\n",
      "Current After:t3_6ohpf2 Round: 24\n",
      "Current After:t3_6je2r9 Round: 25\n",
      "Current After:t3_6embqu Round: 26\n",
      "Current After:t3_690wn3 Round: 27\n",
      "Current After:t3_62osht Round: 28\n",
      "Current After:t3_5wqpxz Round: 29\n",
      "Current After:t3_5qvsoj Round: 30\n",
      "Current After:t3_5mnl9v Round: 31\n",
      "Current After:t3_5if416 Round: 32\n",
      "Limit likely hit.  Returning available posts.\n",
      "asexuality\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9s17gw Round: 1\n",
      "Current After:t3_9ruuex Round: 2\n",
      "Current After:t3_9r6926 Round: 3\n",
      "Current After:t3_9qw9h8 Round: 4\n",
      "Current After:t3_9qfh0m Round: 5\n",
      "Current After:t3_9qg0ea Round: 6\n",
      "Current After:t3_9q0ywc Round: 7\n",
      "Current After:t3_9pqq73 Round: 8\n",
      "Current After:t3_9ovdlb Round: 9\n",
      "Current After:t3_9ovahf Round: 10\n",
      "Current After:t3_9o9wla Round: 11\n",
      "Current After:t3_9o0gyw Round: 12\n",
      "Current After:t3_9npa4a Round: 13\n",
      "Current After:t3_9mwe7k Round: 14\n",
      "Current After:t3_9m9pku Round: 15\n",
      "Current After:t3_9lvrsc Round: 16\n",
      "Current After:t3_9leoev Round: 17\n",
      "Current After:t3_9kxhq4 Round: 18\n",
      "Current After:t3_9ki82f Round: 19\n",
      "Current After:t3_9k2t7f Round: 20\n",
      "Current After:t3_9jkc66 Round: 21\n",
      "Current After:t3_9jboxn Round: 22\n",
      "Current After:t3_9ix3n0 Round: 23\n",
      "Current After:t3_9ic9m6 Round: 24\n",
      "Current After:t3_9i0ywh Round: 25\n",
      "Current After:t3_9hvkjb Round: 26\n",
      "Current After:t3_9h14c9 Round: 27\n",
      "Current After:t3_9gq45l Round: 28\n",
      "Current After:t3_9gelnw Round: 29\n",
      "Current After:t3_9frksy Round: 30\n",
      "Current After:t3_9fcan7 Round: 31\n",
      "Current After:t3_9eph5e Round: 32\n",
      "Current After:t3_9e7n8v Round: 33\n",
      "Current After:t3_9dc77j Round: 34\n",
      "Current After:t3_9cm5y6 Round: 35\n",
      "Current After:t3_9c70ar Round: 36\n",
      "Current After:t3_9bjd43 Round: 37\n",
      "Current After:t3_9b7r3n Round: 38\n",
      "Current After:t3_9aoxsb Round: 39\n",
      "Limit likely hit.  Returning available posts.\n",
      "bisexual\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9sgzo6 Round: 1\n",
      "Current After:t3_9sgjjd Round: 2\n",
      "Current After:t3_9s298y Round: 3\n",
      "Current After:t3_9s0gs6 Round: 4\n",
      "Current After:t3_9ruiur Round: 5\n",
      "Current After:t3_9ryaks Round: 6\n",
      "Current After:t3_9rrzvx Round: 7\n",
      "Current After:t3_9rhfh6 Round: 8\n",
      "Current After:t3_9rg49i Round: 9\n",
      "Current After:t3_9r2vy9 Round: 10\n",
      "Current After:t3_9r7px5 Round: 11\n",
      "Current After:t3_9r0evg Round: 12\n",
      "Current After:t3_9qt3w5 Round: 13\n",
      "Current After:t3_9qq6cg Round: 14\n",
      "Current After:t3_9qgz9d Round: 15\n",
      "Current After:t3_9qmrbh Round: 16\n",
      "Current After:t3_9qja41 Round: 17\n",
      "Current After:t3_9qfdc0 Round: 18\n",
      "Current After:t3_9q73nd Round: 19\n",
      "Current After:t3_9q3k35 Round: 20\n",
      "Current After:t3_9pyu05 Round: 21\n",
      "Current After:t3_9pxl7h Round: 22\n",
      "Current After:t3_9pr5rf Round: 23\n",
      "Current After:t3_9pmn93 Round: 24\n",
      "Current After:t3_9pk0pp Round: 25\n",
      "Current After:t3_9pcgmo Round: 26\n",
      "Current After:t3_9pe5dy Round: 27\n",
      "Current After:t3_9p3use Round: 28\n",
      "Current After:t3_9p37gp Round: 29\n",
      "Current After:t3_9ooytj Round: 30\n",
      "Current After:t3_9oq2lz Round: 31\n",
      "Current After:t3_9oleqd Round: 32\n",
      "Current After:t3_9ogt7u Round: 33\n",
      "Current After:t3_9oawof Round: 34\n",
      "Current After:t3_9o475a Round: 35\n",
      "Current After:t3_9nx6k5 Round: 36\n",
      "Current After:t3_9nx8r4 Round: 37\n",
      "Current After:t3_9nqaw2 Round: 38\n",
      "Current After:t3_9nq0x6 Round: 39\n",
      "Limit likely hit.  Returning available posts.\n",
      "pansexual\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9pl2rh Round: 1\n",
      "Current After:t3_9mx9bb Round: 2\n",
      "Current After:t3_9i2u27 Round: 3\n",
      "Current After:t3_9cmu43 Round: 4\n",
      "Current After:t3_987gpq Round: 5\n",
      "Current After:t3_94gv1x Round: 6\n",
      "Current After:t3_8yt3iy Round: 7\n",
      "Current After:t3_8rwfdx Round: 8\n",
      "Current After:t3_8lao4v Round: 9\n",
      "Current After:t3_8bxf1u Round: 10\n",
      "Current After:t3_7zf494 Round: 11\n",
      "Current After:t3_7mz70c Round: 12\n",
      "Current After:t3_7boadb Round: 13\n",
      "Current After:t3_6yt3vv Round: 14\n",
      "Current After:t3_6l8qf1 Round: 15\n",
      "Current After:t3_67e8mg Round: 16\n",
      "Current After:t3_5uvbif Round: 17\n",
      "Current After:t3_5kei27 Round: 18\n",
      "Current After:t3_57otyd Round: 19\n",
      "Current After:t3_4xnxrl Round: 20\n",
      "Current After:t3_4o5b4i Round: 21\n",
      "Current After:t3_4b5mnu Round: 22\n",
      "Current After:t3_423l8n Round: 23\n",
      "Current After:t3_3rt4hr Round: 24\n",
      "Current After:t3_3izchb Round: 25\n",
      "Current After:t3_3cvngs Round: 26\n",
      "Current After:t3_3103lc Round: 27\n",
      "Current After:t3_2t8wxn Round: 28\n",
      "Current After:t3_2jt3zk Round: 29\n",
      "Current After:t3_28iuad Round: 30\n",
      "Current After:t3_21j645 Round: 31\n",
      "Current After:t3_1uvzbj Round: 32\n",
      "Current After:t3_1n4gl8 Round: 33\n",
      "Current After:t3_1fa8r9 Round: 34\n",
      "Current After:t3_17qrjs Round: 35\n",
      "Current After:t3_12q6lg Round: 36\n",
      "Current After:t3_y09a5 Round: 37\n",
      "Current After:t3_ui6ya Round: 38\n",
      "Current After:t3_of6pc Round: 39\n",
      "Limit likely hit.  Returning available posts.\n",
      "gaygeek\n",
      "Get request successful.\n",
      "Initiating Scrape...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current After:t3_90to33 Round: 1\n",
      "Current After:t3_7ufjz2 Round: 2\n",
      "Current After:t3_6gn2br Round: 3\n",
      "Current After:t3_4vyzqv Round: 4\n",
      "Current After:t3_4bvgf4 Round: 5\n",
      "Current After:t3_3sh06m Round: 6\n",
      "Current After:t3_3556jt Round: 7\n",
      "Current After:t3_2sis32 Round: 8\n",
      "Current After:t3_2ng20s Round: 9\n",
      "Current After:t3_2io8md Round: 10\n",
      "Current After:t3_27fbzb Round: 11\n",
      "Current After:t3_22zhis Round: 12\n",
      "Current After:t3_1we0ld Round: 13\n",
      "Current After:t3_1pz5q8 Round: 14\n",
      "Current After:t3_1ma552 Round: 15\n",
      "Current After:t3_1jl4z6 Round: 16\n",
      "Current After:t3_1i6gfe Round: 17\n",
      "Current After:t3_1ecj08 Round: 18\n",
      "Current After:t3_195uk0 Round: 19\n",
      "Current After:t3_13cs8n Round: 20\n",
      "Current After:t3_zpytz Round: 21\n",
      "Current After:t3_ww8dh Round: 22\n",
      "Current After:t3_u2xty Round: 23\n",
      "Current After:t3_r7tip Round: 24\n",
      "Current After:t3_nkbc9 Round: 25\n",
      "Current After:t3_m5rnq Round: 26\n",
      "Current After:t3_l6gg8 Round: 27\n",
      "Current After:t3_kauia Round: 28\n",
      "Current After:t3_jjmgu Round: 29\n",
      "Current After:t3_iuqsu Round: 30\n",
      "Current After:t3_huwsi Round: 31\n",
      "Current After:t3_hin9g Round: 32\n",
      "Current After:t3_gxi54 Round: 33\n",
      "Current After:t3_etcz6 Round: 34\n",
      "Current After:t3_dj9b5 Round: 35\n",
      "Current After:t3_11pv8s Round: 36\n",
      "Current After:t3_ld54c Round: 37\n",
      "Current After:t3_n5jdu Round: 38\n",
      "Limit likely hit.  Returning available posts.\n",
      "gaymere\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Limit likely hit.  Returning available posts.\n",
      "q4q\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9lfiag Round: 1\n",
      "Current After:t3_9cypz9 Round: 2\n",
      "Current After:t3_9087o5 Round: 3\n",
      "Current After:t3_8ht71j Round: 4\n",
      "Current After:t3_7stnj8 Round: 5\n",
      "Current After:t3_74zkcs Round: 6\n",
      "Current After:t3_6a84hj Round: 7\n",
      "Current After:t3_5gk5k5 Round: 8\n",
      "Current After:t3_4p2c45 Round: 9\n",
      "Current After:t3_44m6ti Round: 10\n",
      "Current After:t3_3owm78 Round: 11\n",
      "Current After:t3_3a532s Round: 12\n",
      "Current After:t3_2yl8qt Round: 13\n",
      "Current After:t3_2n211w Round: 14\n",
      "Current After:t3_2de6wy Round: 15\n",
      "Current After:t3_275nfu Round: 16\n",
      "Current After:t3_1yt27n Round: 17\n",
      "Current After:t3_1txmqo Round: 18\n",
      "Current After:t3_1p0hdc Round: 19\n",
      "Current After:t3_1gbudr Round: 20\n",
      "Current After:t3_1b5k5d Round: 21\n",
      "Current After:t3_166knz Round: 22\n",
      "Current After:t3_11ny43 Round: 23\n",
      "Current After:t3_xqetn Round: 24\n",
      "Current After:t3_uuzmd Round: 25\n",
      "Current After:t3_t51xi Round: 26\n",
      "Current After:t3_pvxig Round: 27\n",
      "Current After:t3_nfzux Round: 28\n",
      "Current After:t3_lphwi Round: 29\n",
      "Current After:t3_jybvt Round: 30\n",
      "Current After:t3_hx6xc Round: 31\n",
      "Current After:t3_fqfi7 Round: 32\n",
      "Current After:t3_ela8p Round: 33\n",
      "Current After:t3_1hg1hg Round: 34\n",
      "Current After:t3_rphgg Round: 35\n",
      "Limit likely hit.  Returning available posts.\n",
      "GaymersGoneMild\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9rytnu Round: 1\n",
      "Current After:t3_9qz9qj Round: 2\n",
      "Current After:t3_9q41y4 Round: 3\n",
      "Current After:t3_9omyjr Round: 4\n",
      "Current After:t3_9nrcr5 Round: 5\n",
      "Current After:t3_9mnopr Round: 6\n",
      "Current After:t3_9kyv96 Round: 7\n",
      "Current After:t3_9k2zgw Round: 8\n",
      "Current After:t3_9iaqsu Round: 9\n",
      "Current After:t3_9hb0gc Round: 10\n",
      "Current After:t3_9g82md Round: 11\n",
      "Current After:t3_9f2pgy Round: 12\n",
      "Current After:t3_9e18ad Round: 13\n",
      "Current After:t3_9cptx1 Round: 14\n",
      "Current After:t3_9c2jj8 Round: 15\n",
      "Current After:t3_9b4hd6 Round: 16\n",
      "Current After:t3_9a39wo Round: 17\n",
      "Current After:t3_98vur1 Round: 18\n",
      "Current After:t3_980myj Round: 19\n",
      "Current After:t3_96zywq Round: 20\n",
      "Current After:t3_9653mr Round: 21\n",
      "Current After:t3_95d75c Round: 22\n",
      "Current After:t3_94faae Round: 23\n",
      "Current After:t3_93aogj Round: 24\n",
      "Current After:t3_92ng8e Round: 25\n",
      "Current After:t3_91okwd Round: 26\n",
      "Current After:t3_90jv32 Round: 27\n",
      "Current After:t3_8zaw23 Round: 28\n",
      "Current After:t3_8y0f51 Round: 29\n",
      "Current After:t3_8wlqss Round: 30\n",
      "Current After:t3_8vg37b Round: 31\n",
      "Current After:t3_8u4jde Round: 32\n",
      "Current After:t3_8swaca Round: 33\n",
      "Current After:t3_8s7xjt Round: 34\n",
      "Current After:t3_8r77pb Round: 35\n",
      "Current After:t3_8pwoim Round: 36\n",
      "Current After:t3_8ojae7 Round: 37\n",
      "Current After:t3_8nf39z Round: 38\n",
      "Current After:t3_8mfkbl Round: 39\n",
      "Limit likely hit.  Returning available posts.\n",
      "lgbtcirclejerk\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_5tapf6 Round: 1\n",
      "Current After:t3_2ago6i Round: 2\n",
      "Current After:t3_1b2dev Round: 3\n",
      "Current After:t3_10p9ne Round: 4\n",
      "Current After:t3_wyddx Round: 5\n",
      "Current After:t3_ufws6 Round: 6\n",
      "Current After:t3_k4cng Round: 7\n",
      "Limit likely hit.  Returning available posts.\n",
      "QPOC\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_2lk4lr Round: 1\n",
      "Limit likely hit.  Returning available posts.\n",
      "TransHack\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_gmut2 Round: 1\n",
      "Limit likely hit.  Returning available posts.\n",
      "QueerFashionAdvice\n",
      "Get request not 200, instead recieved:<Response [404]>\n",
      "QueerTransmen\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_7104ak Round: 1\n",
      "Current After:t3_340zzo Round: 2\n",
      "Current After:t3_vfzl7 Round: 3\n",
      "Current After:t3_czduy Round: 4\n",
      "Current After:t3_c4632 Round: 5\n",
      "Limit likely hit.  Returning available posts.\n",
      "asktransgender\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9shdu9 Round: 1\n",
      "Current After:t3_9sf41r Round: 2\n",
      "Current After:t3_9se6t3 Round: 3\n",
      "Current After:t3_9sccxt Round: 4\n",
      "Current After:t3_9s4067 Round: 5\n",
      "Current After:t3_9s8vz7 Round: 6\n",
      "Current After:t3_9s2ofj Round: 7\n",
      "Current After:t3_9s50nr Round: 8\n",
      "Current After:t3_9ryvd9 Round: 9\n",
      "Current After:t3_9rztxl Round: 10\n",
      "Current After:t3_9rxr8x Round: 11\n",
      "Current After:t3_9ryvts Round: 12\n",
      "Current After:t3_9rfxcu Round: 13\n",
      "Current After:t3_9rka01 Round: 14\n",
      "Current After:t3_9rn9pe Round: 15\n",
      "Current After:t3_9rniky Round: 16\n",
      "Current After:t3_9rgeoh Round: 17\n",
      "Current After:t3_9r8wrr Round: 18\n",
      "Current After:t3_9r4np1 Round: 19\n",
      "Current After:t3_9qxqqk Round: 20\n",
      "Current After:t3_9r617i Round: 21\n",
      "Current After:t3_9r16ql Round: 22\n",
      "Current After:t3_9qzdto Round: 23\n",
      "Current After:t3_9qxwb6 Round: 24\n",
      "Current After:t3_9qu2lo Round: 25\n",
      "Current After:t3_9qrjrt Round: 26\n",
      "Current After:t3_9qrpb6 Round: 27\n",
      "Current After:t3_9qrnhs Round: 28\n",
      "Current After:t3_9qebi4 Round: 29\n",
      "Current After:t3_9qkbq3 Round: 30\n",
      "Current After:t3_9qb91h Round: 31\n",
      "Current After:t3_9qfaf1 Round: 32\n",
      "Current After:t3_9q6nzm Round: 33\n",
      "Current After:t3_9q9s5o Round: 34\n",
      "Current After:t3_9q9jke Round: 35\n",
      "Current After:t3_9q885x Round: 36\n",
      "Current After:t3_9q7h2b Round: 37\n",
      "Current After:t3_9pzb6t Round: 38\n",
      "Current After:t3_9pxiri Round: 39\n",
      "Limit likely hit.  Returning available posts.\n",
      "androgynoushotties\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9qw0g4 Round: 1\n",
      "Current After:t3_9o3k8g Round: 2\n",
      "Current After:t3_9m2mud Round: 3\n",
      "Current After:t3_9jo8jf Round: 4\n",
      "Current After:t3_9huztp Round: 5\n",
      "Current After:t3_9f9cs6 Round: 6\n",
      "Current After:t3_9d92go Round: 7\n",
      "Current After:t3_9aa6ju Round: 8\n",
      "Current After:t3_9878h2 Round: 9\n",
      "Current After:t3_959p2k Round: 10\n",
      "Current After:t3_93de74 Round: 11\n",
      "Current After:t3_91f0gc Round: 12\n",
      "Current After:t3_8zi7xj Round: 13\n",
      "Current After:t3_8vymra Round: 14\n",
      "Current After:t3_8tyina Round: 15\n",
      "Current After:t3_8rol45 Round: 16\n",
      "Current After:t3_8p7wme Round: 17\n",
      "Current After:t3_8nonwp Round: 18\n",
      "Current After:t3_8lpplw Round: 19\n",
      "Current After:t3_8kbnyl Round: 20\n",
      "Current After:t3_8hd1wd Round: 21\n",
      "Current After:t3_8fd4jp Round: 22\n",
      "Current After:t3_8dg72p Round: 23\n",
      "Current After:t3_8b3sf8 Round: 24\n",
      "Current After:t3_86xws4 Round: 25\n",
      "Current After:t3_83ii3c Round: 26\n",
      "Current After:t3_80wdgy Round: 27\n",
      "Current After:t3_7wxbah Round: 28\n",
      "Current After:t3_7so6nw Round: 29\n",
      "Current After:t3_7prfd8 Round: 30\n",
      "Current After:t3_7mypmw Round: 31\n",
      "Current After:t3_7j6w8e Round: 32\n",
      "Current After:t3_7e0gch Round: 33\n",
      "Current After:t3_79t860 Round: 34\n",
      "Current After:t3_77ge68 Round: 35\n",
      "Current After:t3_73nx97 Round: 36\n",
      "Current After:t3_6zwxuv Round: 37\n",
      "Current After:t3_6uya83 Round: 38\n",
      "Current After:t3_6qfkkc Round: 39\n",
      "Limit likely hit.  Returning available posts.\n",
      "GirlGamers\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9re3fe Round: 1\n",
      "Current After:t3_9qg56z Round: 2\n",
      "Current After:t3_9pj916 Round: 3\n",
      "Current After:t3_9on16h Round: 4\n",
      "Current After:t3_9niro1 Round: 5\n",
      "Current After:t3_9mbear Round: 6\n",
      "Current After:t3_9l82sj Round: 7\n",
      "Current After:t3_9kfufe Round: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current After:t3_9jdr7u Round: 9\n",
      "Current After:t3_9ikmha Round: 10\n",
      "Current After:t3_9hq9et Round: 11\n",
      "Current After:t3_9h3egn Round: 12\n",
      "Current After:t3_9gf3qi Round: 13\n",
      "Current After:t3_9f5g9c Round: 14\n",
      "Current After:t3_9eo4tx Round: 15\n",
      "Current After:t3_9deemo Round: 16\n",
      "Current After:t3_9cf1or Round: 17\n",
      "Current After:t3_9blm38 Round: 18\n",
      "Current After:t3_9atoez Round: 19\n",
      "Current After:t3_99ymvt Round: 20\n",
      "Current After:t3_994hab Round: 21\n",
      "Current After:t3_98pv8u Round: 22\n",
      "Current After:t3_98ecf0 Round: 23\n",
      "Current After:t3_97ot6b Round: 24\n",
      "Current After:t3_96wj5m Round: 25\n",
      "Current After:t3_95w261 Round: 26\n",
      "Current After:t3_955kzc Round: 27\n",
      "Current After:t3_944018 Round: 28\n",
      "Current After:t3_92ryfe Round: 29\n",
      "Current After:t3_91njyo Round: 30\n",
      "Current After:t3_90o0ml Round: 31\n",
      "Current After:t3_8zvsd4 Round: 32\n",
      "Current After:t3_8yd53f Round: 33\n",
      "Current After:t3_8x9ane Round: 34\n",
      "Current After:t3_8wf0it Round: 35\n",
      "Current After:t3_8utwb2 Round: 36\n",
      "Current After:t3_8u4dex Round: 37\n",
      "Current After:t3_8t1il3 Round: 38\n",
      "Current After:t3_8s2t2o Round: 39\n",
      "Limit likely hit.  Returning available posts.\n",
      "men\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9k1k64 Round: 1\n",
      "Current After:t3_98sjqj Round: 2\n",
      "Current After:t3_8xt8k9 Round: 3\n",
      "Current After:t3_8p98m4 Round: 4\n",
      "Current After:t3_8e31e8 Round: 5\n",
      "Current After:t3_7xazk6 Round: 6\n",
      "Current After:t3_7czrqv Round: 7\n",
      "Current After:t3_6ivdo3 Round: 8\n",
      "Current After:t3_53qw02 Round: 9\n",
      "Current After:t3_3yjgzq Round: 10\n",
      "Current After:t3_3f6fv6 Round: 11\n",
      "Current After:t3_2wwm4l Round: 12\n",
      "Current After:t3_2q81df Round: 13\n",
      "Current After:t3_2ggmr7 Round: 14\n",
      "Current After:t3_29751s Round: 15\n",
      "Current After:t3_2071rg Round: 16\n",
      "Current After:t3_1hcsz9 Round: 17\n",
      "Current After:t3_18hwjb Round: 18\n",
      "Current After:t3_zmd5n Round: 19\n",
      "Current After:t3_tzvri Round: 20\n",
      "Limit likely hit.  Returning available posts.\n",
      "OneY\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9n29yg Round: 1\n",
      "Current After:t3_9ghne9 Round: 2\n",
      "Current After:t3_98rrhn Round: 3\n",
      "Current After:t3_91yux2 Round: 4\n",
      "Current After:t3_8sqxia Round: 5\n",
      "Current After:t3_8iy7kx Round: 6\n",
      "Current After:t3_8d4csg Round: 7\n",
      "Current After:t3_85k9f9 Round: 8\n",
      "Current After:t3_7y2vpt Round: 9\n",
      "Current After:t3_7t61do Round: 10\n",
      "Current After:t3_7p4pjo Round: 11\n",
      "Current After:t3_7kwd9l Round: 12\n",
      "Current After:t3_7ft8v3 Round: 13\n",
      "Current After:t3_7buwcq Round: 14\n",
      "Current After:t3_77h69p Round: 15\n",
      "Current After:t3_71dai9 Round: 16\n",
      "Current After:t3_6w6fx2 Round: 17\n",
      "Current After:t3_6r1jbs Round: 18\n",
      "Current After:t3_6m84om Round: 19\n",
      "Current After:t3_6hl6qr Round: 20\n",
      "Current After:t3_6dpf4g Round: 21\n",
      "Current After:t3_682gxl Round: 22\n",
      "Current After:t3_603amh Round: 23\n",
      "Current After:t3_5tjgao Round: 24\n",
      "Current After:t3_5lxs1g Round: 25\n",
      "Current After:t3_5hhmd4 Round: 26\n",
      "Current After:t3_5d5klq Round: 27\n",
      "Current After:t3_59uqst Round: 28\n",
      "Current After:t3_57p73g Round: 29\n",
      "Current After:t3_54jcq8 Round: 30\n",
      "Current After:t3_51lr4n Round: 31\n",
      "Current After:t3_4xmv6e Round: 32\n",
      "Current After:t3_4v152q Round: 33\n",
      "Current After:t3_4srgzi Round: 34\n",
      "Current After:t3_4p4l27 Round: 35\n",
      "Current After:t3_4lykyc Round: 36\n",
      "Current After:t3_4jcpfw Round: 37\n",
      "Current After:t3_4hfxtd Round: 38\n",
      "Current After:t3_4fhw2j Round: 39\n",
      "Limit likely hit.  Returning available posts.\n",
      "TwoXChromosomes\n",
      "Get request successful.\n",
      "Initiating Scrape...\n",
      "Current After:t3_9s3970 Round: 1\n",
      "Current After:t3_9s9sr9 Round: 2\n",
      "Current After:t3_9s7juv Round: 3\n",
      "Current After:t3_9rukfb Round: 4\n",
      "Current After:t3_9s5vq1 Round: 5\n",
      "Current After:t3_9rydej Round: 6\n",
      "Current After:t3_9rsn6h Round: 7\n",
      "Current After:t3_9r6i4b Round: 8\n",
      "Current After:t3_9rmiya Round: 9\n",
      "Current After:t3_9rltu7 Round: 10\n",
      "Current After:t3_9revyy Round: 11\n",
      "Current After:t3_9r41kb Round: 12\n",
      "Current After:t3_9qyski Round: 13\n",
      "Current After:t3_9r26ou Round: 14\n",
      "Current After:t3_9qu943 Round: 15\n",
      "Current After:t3_9qtg5x Round: 16\n",
      "Current After:t3_9qnqlo Round: 17\n",
      "Current After:t3_9qtcfu Round: 18\n",
      "Current After:t3_9q02s2 Round: 19\n",
      "Current After:t3_9qhoki Round: 20\n",
      "Current After:t3_9q4h1k Round: 21\n",
      "Current After:t3_9pw1ss Round: 22\n",
      "Current After:t3_9pzjdm Round: 23\n",
      "Current After:t3_9psr3y Round: 24\n",
      "Current After:t3_9poq46 Round: 25\n",
      "Current After:t3_9pd93x Round: 26\n",
      "Current After:t3_9pcztp Round: 27\n",
      "Current After:t3_9pfmsi Round: 28\n",
      "Current After:t3_9p91n4 Round: 29\n",
      "Current After:t3_9oxvx9 Round: 30\n",
      "Current After:t3_9otc59 Round: 31\n",
      "Current After:t3_9orzf4 Round: 32\n",
      "Current After:t3_9ombj9 Round: 33\n",
      "Current After:t3_9oj2s5 Round: 34\n",
      "Current After:t3_9obq60 Round: 35\n",
      "Current After:t3_9o3g9u Round: 36\n",
      "Current After:t3_9o7dw2 Round: 37\n",
      "Limit likely hit.  Returning available posts.\n"
     ]
    }
   ],
   "source": [
    "df_seduction = scrape_reddit('seduction')\n",
    "df_puascience = scrape_reddit('puascience')\n",
    "df_pickup = scrape_reddit('pickup')\n",
    "df_pua = scrape_reddit('pua')\n",
    "df_lgbt = scrape_reddit('lgbt')\n",
    "df_ainbow = scrape_reddit('ainbow')\n",
    "df_AskLGBT = scrape_reddit('AskLGBT')\n",
    "df_happentobegay = scrape_reddit('happentobegay')\n",
    "df_glbt = scrape_reddit('glbt')\n",
    "df_gay = scrape_reddit('gay')\n",
    "df_lgb = scrape_reddit('lgb')\n",
    "df_gayrights = scrape_reddit('gayrights')\n",
    "df_LGBTVent = scrape_reddit('LGBTVent')\n",
    "df_lgbtsex = scrape_reddit('lgbtsex')\n",
    "df_queer = scrape_reddit('queer')\n",
    "df_asexual = scrape_reddit('asexual')\n",
    "df_asexuality = scrape_reddit('asexuality')\n",
    "df_bisexual = scrape_reddit('bisexual')\n",
    "df_pansexual = scrape_reddit('pansexual')\n",
    "df_gaygeek = scrape_reddit('gaygeek')\n",
    "df_gaymers = scrape_reddit('gaymere')\n",
    "df_q4q = scrape_reddit('q4q')\n",
    "df_GaymersGoneMild = scrape_reddit('GaymersGoneMild')\n",
    "df_lgbtcirclejerk = scrape_reddit('lgbtcirclejerk')\n",
    "df_QPOC = scrape_reddit('QPOC')\n",
    "df_TransHack = scrape_reddit('TransHack')\n",
    "df_QueerFashionAdvice = scrape_reddit('QueerFashionAdvice')\n",
    "df_QueerTransmen = scrape_reddit('QueerTransmen')\n",
    "df_asktransgender = scrape_reddit('asktransgender')\n",
    "df_androgynoushotties = scrape_reddit('androgynoushotties')\n",
    "df_GirlGamers = scrape_reddit('GirlGamers')\n",
    "df_men = scrape_reddit('men')\n",
    "df_OneY = scrape_reddit('OneY')\n",
    "df_TwoXChromosomes = scrape_reddit('TwoXChromosomes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seduction.to_csv('seduction_10_30', index = False)\n",
    "#df_puascience.to_csv('puascience_10_30', index = False)\n",
    "df_pickup.to_csv('pickup_10_30', index = False)\n",
    "#df_pua.to_csv('pua_10_30', index = False)\n",
    "df_lgbt.to_csv('lgbt_10_30', index = False)\n",
    "df_ainbow.to_csv('ainbow_10_30', index = False)\n",
    "df_AskLGBT.to_csv('AskLGBT_10_30', index = False)\n",
    "df_happentobegay.to_csv('happentobegay_10_30', index = False)\n",
    "df_glbt.to_csv('glbt_10_30', index = False)\n",
    "df_gay.to_csv('gay_10_30', index = False)\n",
    "#df_lgb.to_csv('lgb_10_30', index = False)\n",
    "df_gayrights.to_csv('gayrights_10_30', index = False)\n",
    "#df_LGBTVent.to_csv('LGBTVent_10_30', index = False)\n",
    "df_lgbtsex.to_csv('lgbtsex_10_30', index = False)\n",
    "df_queer.to_csv('queer_10_30', index = False)\n",
    "df_asexual.to_csv('asexual_10_30', index = False)\n",
    "df_asexuality.to_csv('asexuality_10_30', index = False)\n",
    "df_bisexual.to_csv('bisexual_10_30', index = False)\n",
    "df_pansexual.to_csv('pansexual_10_30', index = False)\n",
    "df_gaygeek.to_csv('gaygeek_10_30', index = False)\n",
    "#df_gaymers.to_csv('gaymere_10_30', index = False)\n",
    "df_q4q.to_csv('q4q_10_30', index = False)\n",
    "df_GaymersGoneMild.to_csv('GaymersGoneMild_10_30', index = False)\n",
    "df_lgbtcirclejerk.to_csv('lgbtcirclejerk_10_30', index = False)\n",
    "#df_QPOC.to_csv('QPOC_10_30', index = False)\n",
    "#df_TransHack.to_csv('TransHack_10_30', index = False)\n",
    "#df_QueerFashionAdvice.to_csv('QueerFashionAdvice_10_30', index = False)\n",
    "df_QueerTransmen.to_csv('QueerTransmen_10_30', index = False)\n",
    "df_asktransgender.to_csv('asktransgender_10_30', index = False)\n",
    "df_androgynoushotties.to_csv('androgynoushotties_10_30', index = False)\n",
    "df_GirlGamers.to_csv('GirlGamers_10_30', index = False)\n",
    "df_men.to_csv('men_10_30', index = False)\n",
    "df_OneY.to_csv('OneY_10_30', index = False)\n",
    "#df_TwoXChromosome.to_csv('TwoXChromosomes_10_30', index = False)\n",
    "#df_lesbians.to_csv('actuallesbians_9_9_400', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the scrappings that we'll be actually using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113.33333333333334"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((5*40)/60)*34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get request successful.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-485789d82fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_lesbians\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_reddit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'actuallesbians'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_incels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_reddit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'braincels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-01363a059796>\u001b[0m in \u001b[0;36mscrape_reddit\u001b[0;34m(the_subreddit, pages)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquick_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Get request successful.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initiating Scrape...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_lesbians = scrape_reddit('actuallesbians')\n",
    "df_incels = scrape_reddit('braincels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Subreddits to check out if there is the opportunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_femcels = scrape_reddit('Trufemcels')\n",
    "#df_gaybros = scrape_reddit('gaybros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Saved and available to be loaded from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "# Export to csv (Commented out to avoid re-saving errors)\n",
    "#df_lesbians.to_csv('actuallesbians_9_9_400', index=False)\n",
    "#df_incels.to_csv('braincels_9_9_400', index=False)\n",
    "#df_femcels.to_csv('trufemcels_9_9_1000', index=False)\n",
    "#df_gaybros.to_csv('gaybros_9_10_540', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from CSV\n",
    "df_lesbians = pd.read_csv('./actuallesbians_9_9_400')\n",
    "df_incels = pd.read_csv('./braincels_9_9_400')\n",
    "#df_femcels = pd.read_csv('./trufemcels_9_9_1000')\n",
    "#df_gaybros = pd.read_csv('./gaybros_9_10_540')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploritory Data Analysis\n",
    "    What are the most used words for each subreddit?\n",
    "    Are the most used words jargon?\n",
    "    How much text on average do the subredditors post?\n",
    "    How many of the posts are pictures?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost No EDA has be done at this time in order to expidite the process of getting this project finished.  That which was mentioned during the presentation was from memory prior to the loss of my previous work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "Using CountVectorizer &/or TF-IDF to generate features from the post text and title of posts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_lesbians['selftext'].apply(text_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiations of the tokenizer, lemmatizer and Count Vectorizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "cvec = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = tokenizer.tokenize,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = 'english') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining and altering the dataframes to be modeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the y Values\n",
    "df_lesbians['is_lesbians'] = 1\n",
    "df_incels['is_lesbians'] = 0\n",
    "\n",
    "# Concatination\n",
    "les_or_inc = pd.concat([df_lesbians.drop('subreddit',axis=1),df_incels.drop('subreddit', axis=1)])\n",
    "\n",
    "# Filling Nulls\n",
    "les_or_inc.fillna('', inplace=True)\n",
    "\n",
    "# Combining the title and selftext columns for easier Count Vectorization\n",
    "les_or_inc['all_text'] = les_or_inc['title'] + ' ' + les_or_inc['selftext']\n",
    "\n",
    "# Resetting the Index\n",
    "les_or_inc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the X,y, as well as the tests and trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y\n",
    "X = les_or_inc['all_text']\n",
    "y = les_or_inc['is_lesbians']\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    random_state=76)\n",
    "# Count Vectorizing the train and test X's while fitting the Training X\n",
    "X_train = pd.DataFrame(cvec.fit_transform(X_train).todense(), columns=cvec.get_feature_names())\n",
    "X_test = pd.DataFrame(cvec.transform(X_test).todense(), columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "source": [
    "The baseline accuracy for this model is about 50% because one could simply guess 1 or 0 for all of the rows and get 50% correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and testing MultinomialNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9513513513513514\n",
      "Test: 0.8704453441295547\n"
     ]
    }
   ],
   "source": [
    "multi_model = MultinomialNB().fit(X_train,y_train)\n",
    "\n",
    "print(\"Train:\", multi_model.score(X_train,y_train))\n",
    "\n",
    "print(\"Test:\", multi_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and testing RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9932432432432432\n",
      "Test: 0.8218623481781376\n"
     ]
    }
   ],
   "source": [
    "rando_forest = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "print(\"Train:\", rando_forest.score(X_train,y_train))\n",
    "\n",
    "print(\"Test:\", rando_forest.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scrapped Code That I didn't want to delete, just incase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "source": [
    "cvec_lesbians['is_lesbians'] = 1\n",
    "cvec_incels['is_lesbians'] = 0\n",
    "\n",
    "les_or_inc = cvec_lesbians.add(cvec_incels, fill_value=0, axis=0)\n",
    "\n",
    "les_or_inc = les_or_inc.fillna(0).astype('int64')\n",
    "\n",
    "X = les_or_inc.drop(columns=['is_lesbians'])\n",
    "y = les_or_inc['is_lesbians']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    random_state=76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_lesbians' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e43e3c16ec04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_lesbians\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selftext'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmysettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mXtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_lesbians' is not defined"
     ]
    }
   ],
   "source": [
    "df = df_lesbians['selftext'].map(text_prep)\n",
    "df = df.apply(text_prep)\n",
    "\n",
    "cvec = CountVectorizer(**mysettings).fit(Xtrain)\n",
    "Xtrain = cvec.transform(Xtrain)\n",
    "Xtest = cvec.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def text_prep(the_text):\n",
    "    the_text = the_text.lower()\n",
    "    the_text = tokenizer.tokenize(the_text)\n",
    "    for i in the_text:\n",
    "        new_text += re.sub(\"[^a-zA-A]\",\" \", i)\n",
    "    new_text = lemmatizer.lemmatize(new_text)\n",
    "    #the_text = [x.split() for x in the_text if not x in stopwords.words('english')]\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A scrapped Function\n",
    "def cvec_it(df):\n",
    "    cvec_selftext = cvec.fit_transform(df['selftext'].fillna(' '))\n",
    "    text_df = pd.DataFrame(cvec_selftext.todense(),columns=cvec.vocabulary_)\n",
    "    cvec_title = cvec.fit_transform(df['title'].fillna(' '))\n",
    "    title_df = pd.DataFrame(cvec_title.todense(),columns=cvec.vocabulary_)\n",
    "    print('concatinating...')\n",
    "    return text_df.add(title_df, fill_value=0, axis=0).astype('int64')\n",
    "cvec_lesbians = cvec_it(df_lesbians)\n",
    "#cvec_femcels = cvec_it(df_femcels)\n",
    "cvec_incels = cvec_it(df_incels)\n",
    "#cvec_gaybros = cvec_it(df_gaybros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Defining the X and y via accedental cvecing before the train/test split\n",
    "# X = cvec.fit_transform(les_or_inc['all_text'])\n",
    "# y = les_or_inc['is_lesbians']\n",
    "\n",
    "#Train Test Split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "#                                                    random_state=76)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train = cvec.transform(X_train)\n",
    "X_test = cvec.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
